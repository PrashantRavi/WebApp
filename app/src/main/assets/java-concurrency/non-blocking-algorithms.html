<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="480">
    <meta name="viewport" content="width=device-width, height=device-height initial-scale=1.0, maximum-scale=1.0, user-scalable=0">

    <title>Non-blocking Algorithms</title>

    <meta name="description" content="This tutorial explains what non-blocking concurrency algorithms are, and how they are different from blocking concurrency algorithms.">
    <meta name="keywords"    content="java concurrency nonblocking algorithms">
    <meta name="author" content="Jakob Jenkov">

    <meta name="twitter:card" content="summary_large_image" >
    <meta name="twitter:site" content="@jjenkov">
    <meta name="twitter:title" content="Non-blocking Algorithms">
    <meta name="twitter:description" content="This tutorial explains what non-blocking concurrency algorithms are, and how they are different from blocking concurrency algorithms.">
    <meta name="twitter:creator" content="@jjenkov">
    <meta name="twitter:domain" content="jenkov.com">

    <meta name="twitter:image:src" content="http://tutorials.jenkov.com/images/java-concurrency/java-concurrency-teaser-500-300.png">

    <meta name="og:type"  content="article"/>
    <meta name="og:title" content="Non-blocking Algorithms"/>
    <meta property="og:url"   content="http://tutorials.jenkov.com/java-concurrency/non-blocking-algorithms.html"/>
    <meta property="og:description" content="This tutorial explains what non-blocking concurrency algorithms are, and how they are different from blocking concurrency algorithms."/>

    <meta property="og:image" content="http://tutorials.jenkov.com/images/java-concurrency/java-concurrency-teaser-500-300.png"/>

    <link href="https://plus.google.com/108227213807945109821" rel="publisher" />

    <meta name="google-site-verification" content="i_TwzdElg-by5uXLvyAjuIaCjxo0yjtW8LdRPUDEEcw" />

    <!-- jQuery -->
    <!--<script src="https://code.jquery.com/jquery-1.12.0.min.js"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>

</head>
<body>
<style>
body {background-color: #f0f0f0;background-image: linear-gradient(180deg, #f0f0f0, #e0e0e0);}
.dataTable th, .dataTable td { padding: 2px 8px; }
</style>
<style id="layoutCss"></style>
<style id="jqcCss"></style>
<style id="articleCss"></style>
<style id="navBarCss"></style>
<style>
code  { font-size: 14px; }
</style>

<script>
lcv = "4";
ls = localStorage;
cacheLoaded = false;
pageLoaded = false;

var prevArticleInCategory = "/java-concurrency/anatomy-of-a-synchronizer.html";
var nextArticleInCategory = "/java-concurrency/amdahls-law.html";
</script>

<script id="jqcJs" ></script>
<script id="bottomNavBarModule" ></script>


<script>
function jsonp(url) {
    var script   = document.createElement("script"); script.type = "text/javascript"; script.src = url;
    document.body.appendChild(script);
}
function insertById(ids) {
    for(var i=0, n=ids.length; i < n; i++) {
        var el = document.getElementById(ids[i]);
        if(el != null) { el.innerHTML = localStorage[ids[i]]; }
    }
}
function insertByClass(ids) {
    for(var i=0, n=ids.length; i<n; i++) {
        var els = document.getElementsByClassName(ids[i]);
        for(var j=0,m=els.length; j<m; j++) { els[j].innerHTML = localStorage[ids[i]]; }
    }
}
function init() {
    if(cacheLoaded == true && pageLoaded == true) {
        console.log("initializing page");
        insertById(["layoutCss", "jqcCss", "topBarLogo", "articleCss", "navBarCss", "bottomNavBar", "bottomNavBarModule", "jqcJs"]);
        insertByClass(["authorPhoto", "authorSocialLinks", "newsletterForm", "googlePlusShare"]);
        $(document).ready(function() { bottomNavBarModule(); });
        console.log("page initialized");
    }
}
if(ls.lcv != lcv) {
    for(var i=0; i < ls.length; i++){
        ls.removeItem(ls.key(i));
    }
    jsonp("/cached-" + lcv + ".js");
    console.log("cache cleared");
} else {
    cacheLoaded = true;
}
ls.lcv = lcv;
</script>
<!-- jqComponents -->


<script>
articleLen = 33862;
adRandom = Math.random() * 100;

function dw(text) { document.write(text); }

function writeAd(adSlot, w, h) {
 dw("<script async src='//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js'><"); dw("/script>");
 dw("<ins class='adsbygoogle' style='display:inline-block;width:" + w + "px;height:" + h + "px' data-ad-client='ca-pub-5569543489255665' data-ad-slot='" +  adSlot + "'></ins>");
 dw("<script>");
 dw("(adsbygoogle = window.adsbygoogle || []).push({});");
 dw("<"); dw("/script>");
}

function topAdStyles(w, mT, mB) {
    var adEl = document.getElementById("topAds");
    adEl.style.width = (w + "px"); adEl.style.marginTop = (mT + "px"); adEl.style.marginBottom = (mB + "px"); adEl.style.marginRight = "auto"; adEl.style.marginLeft = "auto";
}

function bottomAdStyles(elId, w, mT, mB) {
    var adEl = document.getElementById(elId);
    adEl.style.width = (w + "px"); adEl.style.marginTop = (mT + "px"); adEl.style.marginBottom = (mB + "px"); adEl.style.marginRight = "auto"; adEl.style.marginLeft = "auto";
}
</script>


<div id="topBar">
<div jqc-row jqc-row-paddings="0:0 3:24">
    <div jqc-cell="0:12c">
        <div id="topBarContent">
        <div id="topBarLogo"></div>
        <div id="topBarPhrase">Tech and Media Labs</div>
        <div id="topBarMenu">
        <a href="../index.html">Tutorials</a>
        <a href="http://jenkov.com/about/index.html">About</a>
        <a href="http://jenkov.com/rss.xml">RSS</a>
        </div>
        </div>
    </div>
</div>
</div>

<div id="cookieNote">
<div jqc-row jqc-row-widths="0:100% 4:1200" jqc-row-paddings="0:0 3:24">
    <div jqc-cell="0:12c" >
        <div class="card">
            This site uses cookies to improve the user experience. <button onclick="hideCookieNote()">OK</button>
        </div>
    </div>
</div>
</div>

<script>
function hideCookieNote() { document.getElementById("cookieNote").innerHTML = ""; ls.cookieNote = 0; }

if(ls.cookieNote == 0) {
    hideCookieNote();
}
</script>

<div jqc-row jqc-row-widths="0:100% 4:1200" jqc-row-paddings="0:0">
    <div jqc-cell="0:12c">
        <div id="topAds">
            <script>
                var adEl = document.getElementById("topAds");
                if(window.innerWidth > 970) {
                    if(adRandom <= 5){
                        writeAd("6094206201", 970, 90); /* wider ad - 5% of page views */
                        topAdStyles(970, 20, 20);
                    } else {
                        writeAd("7630855405", 728, 90); /* standard ad */
                        topAdStyles(728, 20, 20);
                    }
                } else if(window.innerWidth >= 728 && window.innerWidth <= 970)  {  /* Tutorials - Top Banner */
                    writeAd("7630855405", 728, 90);
                    topAdStyles(728, 20, 20);
                } else {  /* Tutorials - Top Banner - Mobile */
                    writeAd("3297914607", 320, 50);
                    topAdStyles(320, 10, 0);
                }
            </script>
        </div>
    </div>
</div>

<div id="main">

    <div jqc-row jqc-row-widths="0:100% 4:1200" jqc-column-counts="0:24" jqc-row-paddings="0:0 3:24" jqc-cell-spacings="0:8">
        <div jqc-cell="0:0c  3:7c" >
            <div id="trailToc" class="card">
                <div id='trailTitle'>Java Concurrency</div><ol><li><a href="index.html">Java Concurrency / Multithreading Tutorial</a></li><li><a href="benefits.html">Multithreading Benefits</a></li><li><a href="costs.html">Multithreading Costs</a></li><li><a href="concurrency-models.html">Concurrency Models</a></li><li><a href="same-threading.html">Same-threading</a></li><li><a href="concurrency-vs-parallelism.html">Concurrency vs. Parallelism</a></li><li><a href="creating-and-starting-threads.html">Creating and Starting Java Threads</a></li><li><a href="race-conditions-and-critical-sections.html">Race Conditions and Critical Sections</a></li><li><a href="thread-safety.html">Thread Safety and Shared Resources</a></li><li><a href="thread-safety-and-immutability.html">Thread Safety and Immutability</a></li><li><a href="java-memory-model.html">Java Memory Model</a></li><li><a href="synchronized.html">Java Synchronized Blocks</a></li><li><a href="volatile.html">Java Volatile Keyword</a></li><li><a href="threadlocal.html">Java ThreadLocal</a></li><li><a href="thread-signaling.html">Thread Signaling</a></li><li><a href="deadlock.html">Deadlock</a></li><li><a href="deadlock-prevention.html">Deadlock Prevention</a></li><li><a href="starvation-and-fairness.html">Starvation and Fairness</a></li><li><a href="nested-monitor-lockout.html">Nested Monitor Lockout</a></li><li><a href="slipped-conditions.html">Slipped Conditions</a></li><li><a href="locks.html">Locks in Java</a></li><li><a href="read-write-locks.html">Read / Write Locks in Java</a></li><li><a href="reentrance-lockout.html">Reentrance Lockout</a></li><li><a href="semaphores.html">Semaphores</a></li><li><a href="blocking-queues.html">Blocking Queues</a></li><li><a href="thread-pools.html">Thread Pools</a></li><li><a href="compare-and-swap.html">Compare and Swap</a></li><li><a href="anatomy-of-a-synchronizer.html">Anatomy of a Synchronizer</a></li><li><a href="non-blocking-algorithms.html"><b>Non-blocking Algorithms</b></a></li><li><a href="amdahls-law.html">Amdahl's Law</a></li><li><a href="references.html">Java Concurrency References</a></li></ol>
            </div>

            <br><br>
            <!-- Left Bar Adsense Banner Ad -->
            <div id="side-ads">
                <script>
                if(window.innerWidth >= 900){
                    if(adRandom <= 94)     { writeAd("5873880207", 300,  600);}
                    else if(adRandom < 96) { writeAd("3389666608", 160,  600);}
                    else                   { writeAd("4257546205", 300, 1050);}
                }
            </script>
            </div>

            <br><br>


            <div style="display: none;" class="card newsletterForm">
            </div>

        </div>
        <div jqc-cell="0:24c 3:17c" >


            <div class="card">
            <h1>Non-blocking Algorithms</h1>

            <div id="mainBody">

                <div id="pageToc" itemscope itemtype="http://schema.org/SiteNavigationElement">
                    <ul><li><a href="#blocking-concurrency-algorithms">Blocking Concurrency Algorithms</a></li><li><a href="#non-blocking-concurrency-algorithms">Non-blocking Concurrency Algorithms</a></li><li><a href="#nonblocking-vs-blocking-algorithms">Non-blocking vs Blocking Algorithms</a></li><li><a href="#non-blocking-concurrent-data-structures">Non-blocking Concurrent Data Structures</a></li><li><a href="#volatile-variables">Volatile Variables</a><ul><li><a href="#the-single-writer-case">The Single Writer Case</a></li><li><a href="#more-advanced-data-structures-based-on-volatile-variables">More Advanced Data Structures Based on Volatile Variables</a></li></ul></li><li><a href="#optimistic-locking-with-compare-and-swap">Optimistic Locking With Compare and Swap</a><ul><li><a href="#why-is-it-called-optimistic-locking">Why is it Called Optimistic Locking?</a></li><li><a href="#optimistic-locking-is-non-blocking">Optimistic Locking is Non-blocking</a></li></ul></li><li><a href="#non-swappable-data-structures">Non-swappable Data Structures</a><ul><li><a href="#completable-intended-modifications">Completable Intended Modifications</a></li></ul></li><li><a href="#the-a-b-a-problem">The A-B-A Problem</a><ul><li><a href="#a-b-a-solutions">A-B-A Solutions</a></li></ul></li><li><a href="#a-non-blocking-algorithm-template">A Non-blocking Algorithm Template</a></li><li><a href="#non-blocking-algorithms-are-difficult-to-implement">Non-blocking Algorithms are Difficult to Implement</a></li><li><a href="#the-benefit-of-nonblocking-algorithms">The Benefit of Non-blocking Algorithms</a><ul><li><a href="#choice">Choice</a></li><li><a href="#no-deadlocks">No Deadlocks</a></li><li><a href="#no-thread-suspension">No Thread Suspension</a></li><li><a href="#reduced-thread-latency">Reduced Thread Latency</a></li></ul></li></ul>
                </div>
                <div id="lastUpdate">
                    <table><tr><td class="authorPhoto"></td>
                            <td><p style="margin: 0px 0px 6px 0px;">
                                    Jakob Jenkov<br>
                                    Last update: 2015-03-30
                                </p>
                                <div class="authorSocialLinks"></div>
                            </td>
                        </tr>
                    </table>
                </div>

                <p>
    Non-blocking algorithms in the context of concurrency are algorithms that allows threads to access shared state (or otherwise
    collaborate or communicate) without blocking the threads involved. In more general terms, an algorithm is said to be
    non-blocking if the suspension of one thread cannot lead to the suspension of other threads involved in the algorithm.
<p>

<p>
    To better understand the difference between
    blocking and non-blocking concurrency algorithms, I will start by explaining blocking algorithms and then
    continue with non-blocking algorithms.
</p>




<a name="blocking-concurrency-algorithms"></a>
<h2>Blocking Concurrency Algorithms</h2>

<p>
    A blocking concurrency algorithm is an algorithm which either:
</p>

 <ul>
     <li>A: Performs the action requested by the thread - OR</li>
     <li>B: Blocks the thread until the action can be performed safely</li>
 </ul>

<p>
    Many types of algorithms and concurrent data structures are blocking. For instance, the different implementations
    of the <a href="../java-util-concurrent/blockingqueue.html">java.util.concurrent.BlockingQueue</a> interface are
    all blocking data structures. If a thread attempts to insert an element into a <code>BlockingQueue</code> and
    the queue does not have space, the inserting thread is blocked (suspended) until the <code>BlockingQueue</code>
    has space for the new element.
</p>

<p>
    This diagram illustrates the behaviour of a blocking algorithm guarding a shared data structure:
</p>


<img src="../images/java-concurrency/non-blocking-algorithms-1.png" alt="The behaviour of a blocking algorithm guarding a shared data structure.">



<a name="non-blocking-concurrency-algorithms"></a>
<h2>Non-blocking Concurrency Algorithms</h2>

<p>
    A non-blocking concurrency algorithm is an algorithm which either:
</p>

<ul>
    <li>A: Performs the action requested by the thread - OR</li>
    <li>B: Notifies the requesting thread that the action could not be performed</li>
</ul>


<p>
    Java contains several non-blocking data structures too. The <a href="../java-util-concurrent/atomicboolean.html">AtomicBoolean</a>,
    <a href="../java-util-concurrent/atomicinteger.html">AtomicInteger</a>, <a href="../java-util-concurrent/atomiclong.html">AtomicLong</a>
    and <a href="../java-util-concurrent/atomicreference.html">AtomicReference</a> are all examples of non-blocking
    data structures.
</p>

<p>
    This diagram illustrates the behaviour of a non-blocking algorithm guarding a shared data structure:
</p>

<img src="../images/java-concurrency/non-blocking-algorithms-2.png" alt="The behaviour of a non-blocking algorithm guarding a shared data structure.">



<a name="nonblocking-vs-blocking-algorithms"></a>
<h2>Non-blocking vs Blocking Algorithms</h2>

<p>
    The main difference between blocking and non-blocking algorithms lies in the second step of their behaviour as
    described in the above two sections. In other words, the difference lies in what the blocking and non-blocking algorithms do
    when the requested action cannot be performed:
</p>

<p>
    Blocking algorithms block the thread until the requested action can be performed. Non-blocking algorithms notify
    the thread requesting the action that the action cannot be performed.
</p>

<p>
    With a blocking algorithm a thread may become blocked until it is possible to perform the requested action.
    Usually it will be the actions of another thread that makes it possible for the first thread to perform the
    requested action. If for some reason that other thread is suspended (blocked) somewhere else in the application,
    and thus cannot perform the action that makes the first thread's requested action possible, the first thread
    remains blocked - either indefinitely, or until the other thread finally performs the necessary action.
</p>

<p>
    For instance, if a thread tries to insert an element into a full <code>BlockingQueue</code> the thread will block
    until another thread has taken an element from the <code>BlockingQueue</code>.
    If for some reason the thread that is supposed to take elements from the <code>BlockingQueue</code> is blocked
    (suspended) somewhere else in the application, the thread trying to insert the new element remains blocked -
    either indefinitely, or until the thread taking elements finally takes an element from the <code>BlockingQueue</code>.
</p>




<a name="non-blocking-concurrent-data-structures"></a>
<h2>Non-blocking Concurrent Data Structures</h2>

<p>
    In a multithreaded system, threads usually communicate via some kind of data structure. Such data structures can be anything from simple variables
    to more advanced data structures like queues, maps, stacks etc. To facilitate correct, concurrent access to the data structures
    by multiple threads, the data structures must be guarded by some <i>concurrent algorithm</i>. The guarding algorithm
    is what makes the data structure a <i>concurrent data structure</i>.
</p>

<p>
    If the algorithm guarding a concurrent data structure is blocking (uses thread suspension), it is said to be a
    <i>blocking algorithm</i>. The data structure is thus said to be a <i>blocking, concurrent data structure</i>.
</p>

<p>
    If the algorithm guarding a concurrent data structure is non-blocking, it is said to be a <i>non-blocking algorithm</i>.
    The data structure is thus said to be a <i>non-blocking, concurrent data structure</i>.
</p>

<p>
    Each concurrent data structure is designed to support a certain method of communication. Which concurrent data structure
    you can use thus depends on your communication needs. I will cover some non-blocking concurrent
    data structures in the following sections, and explain in what situations they can be used. The explanation of
    how these non-blocking data structures work should give you an idea about how non-blocking data structures can be
    designed and implemented.
</p>




<a name="volatile-variables"></a>
<h2>Volatile Variables</h2>


<p>
    <a href="volatile.html">Java volatile variables</a> are variables that are always read directly from main memory.
    When a new value is assigned to a volatile variable the value is always written immediately to main memory.
    This guarantees that the latest value of a volatile variable is always visible to other threads running on
    other CPUs. Other threads will read the value of the volatile from main memory every time, instead of from e.g.
    the CPU cache of the CPU the threads are running on.
</p>

<p>
    Volatile variables are non-blocking. The writing of a value to a volatile variable is an atomic operation.
    It cannot be interrupted. However, a read-update-write sequence performed on a volatile variable is not atomic.
    Thus, this code may still lead to <a href="race-conditions-and-critical-sections.html">race conditions</a> if performed by more than one thread:
</p>

<pre class="codeBox">
volatile myVar = 0;

...
int temp = myVar;
temp++;
myVar = temp;
</pre>

<p>
    First the value of the volatile variable <code>myVar</code> is read from main memory into a temp variable. Then the
    temp variable is incremented by 1. Then the value of the temp variable is assigned to the volatile <code>myVar</code>
    variable which means it will be written back to main memory.
</p>

<p>
    If two threads execute this code and both of them read the value of <code>myVar</code>, add one to it and write
    the value back to main memory, then you risk that instead of 2 being added to the <code>myVar</code> variable,
    only 1 will be added (e.g. both threads read the value 19, increment to 20, and write 20 back).
</p>

<p>
    You might think you won't write code like above, but in practice the above code is equivalent to this:
</p>

<pre class="codeBox">
myVar++;
</pre>

<p>
    When executed, the value of <code>myVar</code> is read into a
    CPU register or the local CPU cache, one is added, and then the value from the CPU register or CPU cache is written
    back to main memory.
</p>



<a name="the-single-writer-case"></a>
<h3>The Single Writer Case</h3>

<p>
    In some cases you only have a single thread writing to a shared variable, and multiple threads reading the value
    of that variable. No race conditions can occur when only a single thread is updating a variable, no matter how
    many threads are reading it. Therefore, whenever you have only a single writer of a shared variable you can use
    a volatile variable.
</p>

<p>
    The race conditions occur when multiple threads perform a read-update-write sequence of operations on a shared
    variable. If you only have one thread perform a read-update-write sequence of operations, and all other threads
    only perform a read operation, you have no race conditions.
</p>

<p>
    Here is a single writer counter which does not use synchronization but is still concurrent:
</p>


<pre class="codeBox">
public class SingleWriterCounter {

    private volatile long count = 0;

    /**
     * Only one thread may ever call this method,
     * or it will lead to race conditions.
     */
    public void inc() {
        this.count++;
    }


    /**
     * Many reading threads may call this method
     * @return
     */
    public long count() {
        return this.count;
    }
}
</pre>


<p>
    Multiple threads can access the same instance of this counter, as long as only one thread calls <code>inc()</code>.
    And I don't mean one thread at a time. I mean, only the same, single thread is ever allowed to call <code>inc()</code>.
    Multiple threads can call <code>count()</code>. This will not cause any race conditions.
</p>

<p>
    This diagram illustrates how the threads would access the volatile <code>count</code> variable:
</p>

<img src="../images/java-concurrency/non-blocking-algorithms-3.png" alt="Single writer, multiple reader threads communicating via a volatile variable.">





<a name="more-advanced-data-structures-based-on-volatile-variables"></a>
<h3>More Advanced Data Structures Based on Volatile Variables</h3>

<p>
    It is possible to create data structures that use combinations of volatile variables, where each volatile variable
    is only written by a single thread, and read by multiple threads. Each volatile variable may be written by a different
    thread (but only one thread). Using such a data structure multiple threads may be able to send information to each
    other in a non-blocking way, using the volatile variables.
</p>

<p>
    Here is a simple double writer counter class that shows how that could look:
</p>


<pre class="codeBox">
public class DoubleWriterCounter {

    private volatile long countA = 0;
    private volatile long countB = 0;

    /**
     * Only one (and the same from thereon) thread may ever call this method,
     * or it will lead to race conditions.
     */
    public void incA() { this.countA++;  }


    /**
     * Only one (and the same from thereon) thread may ever call this method,
     * or it will lead to race conditions.
     */
    public void incB() { this.countB++;  }


    /**
     * Many reading threads may call this method
     */
    public long countA() { return this.countA; }


    /**
     * Many reading threads may call this method
     */
    public long countB() { return this.countB; }
}
</pre>


<p>
    As you can see, the <code>DoubleWriterCounter</code> now contains two volatile variables, and two pairs of incrementation
    and read methods. Only a single thread may ever call <code>incA()</code>, and only a single thread may ever call
    <code>incB()</code>. It can be different threads calling <code>incA()</code> and <code>incB()</code> though.
    Many threads are allowed to call <code>countA()</code> and <code>countB()</code>. This will not cause race conditions.
</p>

<p>
    The <code>DoubleWriterCounter</code> can be used for e.g. two threads communicating. The two counts could be
    tasks produced and tasks consumed. This diagram shows two thread communicating via a data structure similar to
    the above:
</p>

<img src="../images/java-concurrency/non-blocking-algorithms-4.png" alt="Single writer, multiple reader threads communicating via a volatile variable.">



<p>
    The smart reader will recognize that you could have achieved the effect of the <code>DoubleWriterCounter</code>
    by using two <code>SingleWriterCounter</code> instances. You could even have used more threads and
    <code>SingleWriterCounter</code> instances if you needed to.
</p>




<a name="optimistic-locking-with-compare-and-swap"></a>
<h2>Optimistic Locking With Compare and Swap</h2>

<p>
    If you really need more than one thread to write to the same, shared variable, a volatile variable will not be sufficient.
    You will need some kind of exclusive access to the variable. This is how such exclusive access could look
    using a <a href="synchronized.html">synchronized block in Java</a>:
</p>


<pre class="codeBox">
public class SynchronizedCounter {
    long count = 0;

    public void inc() {
        synchronized(this) {
            count++;
        }
    }

    public long count() {
        synchronized(this) {
            return this.count;
        }
    }
}
</pre>

<p>
    Notice how the <code>inc()</code> and <code>count()</code> methods both contain a synchronized block. This is what
    we want to avoid - synchronized blocks and <code>wait()</code> - <code>notify()</code> calls etc.
</p>

<p>
    Instead of the two synchronized blocks we can use one of Java's atomic variables. In this case the <code>AtomicLong</code>.
    Here is how the same counter class could look using an <code>AtomicLong</code> instead:
</p>

<pre class="codeBox">
import java.util.concurrent.atomic.AtomicLong;

public class AtomicCounter {
    private AtomicLong count = new AtomicLong(0);

    public void inc() {
        boolean updated = false;
        while(!updated){
            long prevCount = this.count.get();
            updated = this.count.compareAndSet(prevCount, prevCount + 1);
        }
    }

    public long count() {
        return this.count.get();
    }
}
</pre>


<p>
    This version is just as thread-safe as the previous version. What is interesting about this version is the
    implementation of the <code>inc()</code> method. The <code>inc()</code> method no longer contains a synchronized
    block. Instead it contains these lines:
</p>

<pre class="codeBox">
boolean updated = false;
while(!updated){
    long prevCount = this.count.get();
    updated = this.count.compareAndSet(prevCount, prevCount + 1);
}
</pre>

<p>
    These lines are not an atomic operation. That means, that it is possible for two different threads to call
    the <code>inc()</code> method and execute the <code>long prevCount = this.count.get()</code> statement, and thus
    both obtain the previous count for the counter. Yet, the above code does not contain any race conditions.
</p>

<p>
    The secret is in the second of the two lines inside the <code>while</code> loop. The <code>compareAndSet()</code>
    method call is an atomic operation. It compares the internal value of the <code>AtomicLong</code> to an expected
    value, and if the two values are equal, sets a new internal value for the <code>AtomicLong</code>. The
    <code>compareAndSet()</code> method is typically supported by compare-and-swap instructions directly in the CPU.
    Therefore no synchronization is necessary, and no thread suspension is necessary. This saves the thread suspension
    overhead.
</p>

<p>
    Imagine that the internal value of the <code>AtomicLong</code> is 20. Then two threads read that value, and both
    tries to call <code>compareAndSet(20, 20 + 1)</code>. Since <code>compareAndSet()</code> is an atomic operation,
    the threads will execute this method sequentially (one at a time).
</p>

<p>
    The first thread will compare the expected
    value of 20 (the previous value of the counter) to the internal value of the <code>AtomicLong</code>. Since the
    two values are equal, the <code>AtomicLong</code> will update its internal value to 21 (20 + 1). The
    <code>updated</code> variable will be set to <code>true</code> and the <code>while</code> loop will stop.
</p>

<p>
    Now the second thread calls <code>compareAndSet(20, 20 + 1)</code>. Since the internal value of the <code>AtomicLong</code>
    is no longer 20, this call will fail. The internal value of the <code>AtomicLong</code> will not be set to 21.
    The <code>updated</code> variable will be set to <code>false</code>, and the thread will spin one more time around
    the <code>while</code> loop. This time it will read the value 21 and attempt to update it to 22. If no other thread has called
    <code>inc()</code> in the meantime, the second iteration will succeed in updating the <code>AtomicLong</code> to
    22.
</p>




<a name="why-is-it-called-optimistic-locking"></a>
<h3>Why is it Called Optimistic Locking?</h3>
<p>
    The code shown in the previous section is called <i>optimistic locking</i>. Optimistic locking is different from
    traditional locking, sometimes also called pessimistic locking. Traditional locking blocks the access
    to the shared memory with a synchronized block or a lock of some kind. A synchronized block or lock may result in
    threads being suspended.
</p>

<p>
    Optimistic locking allows all threads to create a copy of the shared memory without
    any blocking. The threads may then make modifications to their copy, and attempt to write their modified version
    back into the shared memory. If no other thread has made any modifications to the shared memory, the compare-and-swap
    operation allows the thread to write its changes to shared memory. If another thread has already changed the
    shared memory, the thread will have to obtain a new copy, make its changes and attempt to write them to shared
    memory again.
</p>

<p>
    The reason this is called optimistic locking is that threads obtain a copy of the data they want
    to change and apply their changes, under the optimistic assumption that no other thread will
    have made changes to the shared memory in the meantime. When this optimistic assumption holds true, the thread
    just managed to update shared memory without locking. When this assumption is false, the work was wasted, but still
    no locking was applied.
</p>

<p>
    Optimistic locking tends to work best with low to medium contention on the shared memory. If the content is very
    high on the shared memory, threads will waste a lot of CPU cycles copying and modifying the shared memory only
    to fail writing the changes back to the shared memory. But, if you have a lot of content on shared memory, you
    should anyways consider redesigning your code to lower the contention.
</p>




<a name="optimistic-locking-is-non-blocking"></a>
<h3>Optimistic Locking is Non-blocking</h3>

<p>
    The optimistic locking mechanism I have shown here is non-blocking. If a thread obtains a copy of the shared
    memory and gets blocked (for whatever reason) while trying to modify it, no other threads are blocked from accessing
    the shared memory.
</p>

<p>
    With a traditional lock / unlock paradigm, when a thread locks a lock - that lock remains locked for all other
    threads until the thread owning the lock unlocks it again. If the thread that locked the lock is blocked somewhere
    else, that lock remains locked for a very long time - maybe even indefinitely.
</p>




<a name="non-swappable-data-structures"></a>
<h2>Non-swappable Data Structures</h2>

<p>
    The simple compare-and-swap optimistic locking works for shared data structures where the whole data structure
    can be swapped (exchanged) with a new data structure in a single compare-and-swap operation. Swapping the whole
    data structure with a modified copy may not always be possible or feasible, though.
</p>

<p>
    Imagine if the shared data structure is a queue. Each thread trying to either insert or take elements from the
    queue would have to copy the whole queue and make the desired modifications to the copy. This could be achieved via
    an <code>AtomicReference</code>. Copy the reference, copy and modify the queue, and try to swap the reference pointed
    to in the <code>AtomicReference</code> to the newly created queue.
</p>

<p>
    However, a big data structure may require a lot of memory and CPU cycles to copy. This will make your application
    spend a lot more memory, and waste a lot of time on the copying. This will impact the performance of your
    application, especially if contention on the data structure is high. Furthermore, the longer time it takes for a
    thread to copy and modify the data structure, the bigger the probability is that some other thread will have modified
    the data structure in between. As you know, if another thread has modified the shared data structure since it was
    copied, all other threads have to restart their copy-modify operations. This will increase the impact on performance
    and memory consumption even more.
</p>

<p>
    The next section will explain a method to implement non-blocking data structures which can be updated concurrently,
    not just copied and modified.
</p>




<h2>Sharing Intended Modifications</h2>

<p>
    Instead of copying and modifying the whole shared data structure, a thread can share its <i>intended modification</i>
    of the shared data structure. The process for a thread wanting to make a modification to the shared data structure
    then becomes:
</p>


<ol>
    <li>Check if another thread has submitted an intended modification to the data structure.</li>
    <li>If no other thread has submitted an intended modification, create an intended modification (represented by an object)
        and submit that intended modification to the data structure (using a compare-and-swap operation).
    </li>
    <li>
        Carry out the modification of the shared data structure.
    </li>

    <li>
        Remove the reference to the intended modification to signal to other threads that the intended modification
        has been carried out.
    </li>
</ol>


<p>
    As you can see, the second step can block other threads from submitting an intended modification. Thus, the
    second step effectively works as a lock of the shared data structure. If one thread successfully submits an
    intended modification, no other thread can submit an intended modification until the first intended modification
    is carried out.
</p>

<p>
    If a thread submits an intended modification and then gets blocked doing some other work, the shared data structure
    is effectively locked. The shared data structure does not directly block the other threads using the data structure.
    The other threads can detect that they cannot submit an intended modification and decide to something else.
    Obviously, we need to fix that.
</p>




<a name="completable-intended-modifications"></a>
<h3>Completable Intended Modifications</h3>

<p>
    To avoid that a submitted intended modification can lock the shared data structure, a submitted intended modification
    object must contain enough information for another thread to complete the modification. Thus, if the thread submitting
    the intended modification never completes the modification, another thread can complete the modification on its behalf,
    and keep the shared data structure available for other threads to use.
</p>

<p>
    Here is a diagram illustrating the blueprint of the above described non-blocking algorithm:
</p>

<img src="../images/java-concurrency/non-blocking-algorithms-5.png" alt="A non-blocking algorithm blueprint using completable intended modifications">

<p>
    The modifications must be carried out as one or more compare-and-swap operations. Thus, if two threads
    try to complete the intended modification, only one thread will be able to carry out any of the compare-and-swap
    operations. As soon as a compare-and-swap operation has been completed, further attempts to complete that compare-and-swap
    operation will fail.
</p>




<a name="the-a-b-a-problem"></a>
<h2>The A-B-A Problem</h2>

<p>
    The above illustrated algorithm can suffer from the A-B-A problem. The A-B-A problem refers to the situation where
    a variable is changed from A to B and then back to A again. For another thread it is thus not possible to detect
    that the variable was indeed changed.
</p>

<p>
    If thread A checks for ongoing updates, copies data and is suspended by the thread scheduler, a thread B may
    be able to access the shared data structure in the meanwhile. If thread B performs a full update of the data structure,
    and removes its intended modification, it will look to thread A as if no modification has taken place since it
    copied the data structure. However, a modification did take place. When thread A continues to perform its update
    based on its now out-of-date copy of the data structure, the data structure will have thread B's modification undone.
</p>

<p>
    The following diagram illustrates A-B-A problem from the above situation:
</p>

<img src="../images/java-concurrency/non-blocking-algorithms-6.png" alt="The A-B-A problem which can occur with completable intended modifications.">




<a name="a-b-a-solutions"></a>
<h3>A-B-A Solutions</h3>
<p>
    A common solution to the A-B-A problem is to not just swap a pointer to an intended modification object, but
    to combine the pointer with a counter, and swap pointer + counter using a single compare-and-swap operation.
    This is possible in languages that support pointers like C and C++. Thus, even if the current modification pointer
    is set back to point to "no ongoing modification", the counter part of the pointer + counter will have
    been incremented, making the update visible to other threads.
</p>

<p>
    In Java you cannot merge a reference and a counter together into a single variable. Instead Java provides
    the <a href="../java-util-concurrent/atomicstampedreference.html"><code>AtomicStampedReference</code></a> class
    which can swap a reference and a stamp atomically using a compare-and-swap operation.
</p>




<a name="a-non-blocking-algorithm-template"></a>
<h2>A Non-blocking Algorithm Template</h2>

<p>
    Below is a code template intended to give you an idea about how non-blocking algorithms are implemented.
    The template is based on the descriptions given earlier in this tutorial.
</p>

<p>
    NOTE: I am not an expert in non-blocking algorithms, so the template below probably has some errors.
    Do not base your own non-blocking algorithm implementation on my template. The template is only intended
    to give you an idea of how the code for a non-blocking algorithm could look. If you want to implement
    your own non-blocking algorithms, study some real, working non-blocking algorithm implementations
    first, to learn more about how they are implemented in practice.
</p>

<pre class="codeBox">
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicStampedReference;

public class NonblockingTemplate {

    public static class IntendedModification {
        public AtomicBoolean completed =
                new AtomicBoolean(false);
    }

    private AtomicStampedReference&lt;IntendedModification&gt;
        ongoingMod =
            new AtomicStampedReference&lt;IntendedModification&gt;(null, 0);

    //declare the state of the data structure here.


    public void modify() {
        while(!attemptModifyASR());
    }

    public boolean attemptModifyASR(){

        boolean modified = false;
    
        IntendedModification currentlyOngoingMod =
        ongoingMod.getReference();
        int stamp = ongoingMod.getStamp();
    
        if(currentlyOngoingMod == null){
            //copy data structure state - for use
            //in intended modification
        
            //prepare intended modification
            IntendedModification newMod =
            new IntendedModification();
        
            boolean modSubmitted = 
                ongoingMod.compareAndSet(null, newMod, stamp, stamp + 1);
        
            if(modSubmitted){
            
                //complete modification via a series of compare-and-swap operations.
                //note: other threads may assist in completing the compare-and-swap
                // operations, so some CAS may fail
            
                modified = true;
            }
    
        } else {
            //attempt to complete ongoing modification, so the data structure is freed up
            //to allow access from this thread.
        
            modified = false;
        }
    
        return modified;
    }
}
</pre>



<a name="non-blocking-algorithms-are-difficult-to-implement"></a>
<h2>Non-blocking Algorithms are Difficult to Implement</h2>
<p>
    Non-blocking algorithms are hard to design and implement correctly. Before attempting to implement your
    own non-blocking algorithms, see if there is not someone who has already developed a non-blocking algorithm for
    your needs.
</p>

<p>
    Java already comes with a few non-blocking implementations (e.g. <code>ConcurrentLinkedQueue</code>) and
    will most likely get more non-blocking algorithm implementations in future Java versions.
</p>

<p>
    In addition to Java's built-in non-blocking data structures there are also some open source non-blocking data structures
    you can use. For instance, the LMAX Disrupter (a queue-like data structure), and the non-blocking HashMap from Cliff Click. See
    my <a href="references.html">Java concurrency references page</a> for links to more resources.
</p>




<a name="the-benefit-of-nonblocking-algorithms"></a>
<h2>The Benefit of Non-blocking Algorithms</h2>

<p>
    There are several benefits of non-blocking algorithms compared to blocking algorithms. This section will
    describe these benefits.
</p>





<a name="choice"></a>
<h3>Choice</h3>
<p>
    The first benefit of non-blocking algorithms is, that threads are given a choice about what to do when their
    requested action cannot be performed. Instead of just being blocked, the request thread has a choice about what
    to do. Sometimes there is nothing a thread can do. In that case it can choose to block or wait itself, thus
    freeing up the CPU for other tasks. But at least the requesting thread is given a choice.
</p>

<p>
    On a single CPU system perhaps it makes sense to suspend a thread that cannot perform a desired action, and
    let other threads which can perform their work run on the CPU. But even on a single CPU system blocking algorithms
    may lead to problems like <a href="deadlock.html">deadlock</a>, <a href="starvation-and-fairness.html">starvation</a>
    and other concurrency problems.
</p>




<a name="no-deadlocks"></a>
<h3>No Deadlocks</h3>
<p>
    The second benefit of non-blocking algorithms is, that the suspension of one thread cannot lead to the suspension
    of other threads. This means that deadlock cannot occur. Two threads cannot be blocked waiting for each other to
    release a lock they want. Since threads are not blocked when they cannot perform their requested action, they
    cannot be blocked waiting for each other. Non-blocking algorithms may still result in live lock, where two threads
    keep attempting some action, but keep being told that it is not possible (because of the actions of the other thread).
</p>




<a name="no-thread-suspension"></a>
<h3>No Thread Suspension</h3>

<p>
    Suspending and reactivating a thread is costly. Yes, the costs of suspension and reactivation has gone down over
    time as operating systems and thread libraries become more efficient. However, there is still a high price to
    pay for thread suspension and reactivation.
</p>

<p>
    Whenever a thread is blocked it is suspended, thus incurring the overhead of thread suspension and reactivation.
    Since threads are not suspended by non-blocking algorithms, this overhead does not occur. This means that the
    CPUs can potentially spend more time performing actual business logic instead of context switching.
</p>

<p>
    On a multi CPU system blocking algorithms can have more significant impact on the overall performance.
    A thread running on CPU A can be blocked waiting for a thread running on CPU B. This lowers the level of parallelism
    the application is capable of achieving. Of course, CPU A could just schedule another thread to run,
    but suspending and activating threads (context switches) are expensive. The less threads need to be suspended
    the better.
</p>




<a name="reduced-thread-latency"></a>
<h3>Reduced Thread Latency</h3>

<p>
    Latency in this context means the time between a requested action becomes possible and the thread actually
    performs it. Since threads are not suspended in non-blocking algorithms they do not have to pay the expensive, slow
    reactivation overhead. That means that when a requested action becomes possible threads can respond faster and
    thus reduce their response latency.
</p>

<p>
    The non-blocking algorithms often obtain the lower latency by busy-waiting until the requested action becomes
    possible. Of course, in a system with high thread contention on the non-blocking data structure, CPUs may end up
    burning a lot of cycles during these busy waits. This is a thing to keep in mind. Non-blocking algorithms may
    not be the best if your data structure has high thread contention. However, there are often ways do redesign your
    application to have less thread contention.
</p>

                <div>
                </div>

                <div id="next">Next: <a href="amdahls-law.html">Amdahl's Law</a></div>
                <div id="bottomSocial">

                    <div style="display:inline-block;">
                        <table>
                            <tr><td colspan="2">
                                <div class='g-plus' data-action='share' data-height='24'  data-annotation='none'></div>
                                <script type='text/javascript'>
                                    (function() {
                                        var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
                                        po.src = 'https://apis.google.com/js/platform.js';
                                        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
                                     })();
                                </script>

                                <a href='https://twitter.com/share' class='twitter-share-button' data-via='jjenkov' target="_blank">Tweet</a>
                                <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

                            </td></tr>
                            <tr><td class="authorPhoto"></td><td><p style="margin: 0px 0px 6px 0px;">Jakob Jenkov</p><div class="authorSocialLinks"></div></td></tr>
                        </table>
                    </div>

                    <div  style="display: none;" class="newsletterForm"  style="display:inline-block;"></div>

                </div>
            </div>
            </div>
        </div>
    </div>

</div>

<!-- Bottom ads - (nested row is working, but should perhaps not be a nested row?) (note: was a nested row in old design - not in new) -->
<div jqc-row jqc-row-paddings="0:0">
    <div jqc-cell="0:12c">
        <div id="pageBottomAds">
            <script>
                    if(articleLen >= 4000){ /* for longer articles place ads here, at the bottom of the page */
                        if(window.innerWidth >= 728 ) {  /* Adsense Ads - Bottom Banner */
                            if(adRandom < 5)       { writeAd("2721937400", 970, 90);  bottomAdStyles("pageBottomAds", 970, 20, 20);}
                            else if(adRandom < 30) { writeAd("9547200207", 970, 250); bottomAdStyles("pageBottomAds", 970, 20, 20);}
                            else                   { writeAd("7776167002", 728, 90);  bottomAdStyles("pageBottomAds", 728, 20, 20);}
                        } else if(window.innerWidth < 728) {  /* Adsense Ads - Bottom Banner - Mobile */
                            if(adRandom < 50) {
                                writeAd("4216244607", 320, 50); bottomAdStyles("pageBottomAds", 320, 10, 0);
                            } else {
                                writeAd("7377085404", 320, 100); bottomAdStyles("pageBottomAds", 320, 10, 0);
                            }
                        }
                    }
                </script>
            <br/><br/><br/>
        </div>


        <div style="height: 30px"></div>
        <div id="disqusComments" class="card">
            <div id="disqus_thread"></div>
            <script type="text/javascript">
                var disqus_shortname = 'tutorials-jenkov-com'; // required: replace example with your forum shortname

                /* * * DON'T EDIT BELOW THIS LINE * * */
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        </div>

    </div>
</div>

<span id="layoutManager" jqc-type="jqcResponsiveLayoutManager" jqc-row-paddings="0:8 4:0"></span>


<div id="footerBar">
<div jqc-row>
    <div jqc-cell="0:12c">
        Copyright &nbsp;Jenkov Aps
    </div>
</div>
</div>

<div id="trailTocFixedDiv">
  <div id="trailTocFixedCloseButton">Close TOC</div>
  <div id="trailTocFixedInnerDiv"></div>
</div>
<div id="bottomNavBar"></div>

<!-- init page -->
<script>
pageLoaded = true;
init();
</script>


<!-- Google Analytics Script -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-4036229-3', 'auto');
  ga('send', 'pageview');

</script>


</body>
</html>
<!-- Localized -->